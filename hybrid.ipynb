{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Restaurant  Sentiment_Score\n",
      "0               10 Downing Street             0.86\n",
      "1                        13 Dhaba             0.67\n",
      "2  3B's - Buddies, Bar & Barbecue             0.94\n",
      "3       AB's - Absolute Barbecues             0.98\n",
      "4               Absolute Sizzlers             0.68\n",
      "          Restaurant             Similar_Restaurant  Content_Score\n",
      "0  10 Downing Street                          SKYHY       0.675805\n",
      "1  10 Downing Street         Mustang Terrace Lounge       0.672156\n",
      "2  10 Downing Street  The Lal Street - Bar Exchange       0.659896\n",
      "3  10 Downing Street     La La Land - Bar & Kitchen       0.637958\n",
      "4  10 Downing Street     Over The Moon Brew Company       0.631628\n",
      "          Restaurant                    Similar_Restaurant  Item_CF_Score\n",
      "0  10 Downing Street                    Hunger Maggi Point       0.232301\n",
      "1  10 Downing Street                         Gal Punjab Di       0.172412\n",
      "2  10 Downing Street  Collage - Hyatt Hyderabad Gachibowli       0.136376\n",
      "3  10 Downing Street                                Faasos       0.096689\n",
      "4  10 Downing Street                       The Glass Onion       0.075676\n"
     ]
    }
   ],
   "source": [
    "sentiment_path = \"data hybrid/sentiment_scores.csv\" \n",
    "content_path = \"data hybrid/content_scores.csv\"\n",
    "item_cf_path = \"data hybrid/item_cf_scores.csv\"\n",
    "\n",
    "sentiment_scores = pd.read_csv(sentiment_path) \n",
    "content_scores = pd.read_csv(content_path)  \n",
    "item_cf_scores = pd.read_csv(item_cf_path) \n",
    "\n",
    "print(sentiment_scores.head())\n",
    "print(content_scores.head())\n",
    "print(item_cf_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hybird model of sentiment analysis + content-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Restaurant             Similar_Restaurant  Content_Score  \\\n",
      "4   10 downing street     over the moon brew company       0.722478   \n",
      "2   10 downing street  the lal street - bar exchange       0.757282   \n",
      "0   10 downing street                          skyhy       0.776870   \n",
      "1   10 downing street         mustang terrace lounge       0.772377   \n",
      "10  10 downing street           prism club & kitchen       0.651262   \n",
      "\n",
      "    Sentiment_Score  Hybrid_Score  \n",
      "4          0.907692      0.778042  \n",
      "2          0.646154      0.723944  \n",
      "0          0.600000      0.723809  \n",
      "1          0.569231      0.711433  \n",
      "10         0.830769      0.705114  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Normalize restaurant names for consistency\n",
    "for df in [sentiment_scores, content_scores]:\n",
    "    df[\"Restaurant\"] = df[\"Restaurant\"].str.strip().str.lower()\n",
    "    if \"Similar_Restaurant\" in df.columns:\n",
    "        df[\"Similar_Restaurant\"] = df[\"Similar_Restaurant\"].str.strip().str.lower()\n",
    "\n",
    "# Merge content-based filtering scores with sentiment scores of the similar restaurant\n",
    "hybrid_model = content_scores.merge(sentiment_scores, left_on=\"Similar_Restaurant\", right_on=\"Restaurant\", how=\"left\")\n",
    "\n",
    "# Drop duplicate Restaurant column\n",
    "hybrid_model = hybrid_model.drop(columns=[\"Restaurant_y\"]).rename(columns={\"Restaurant_x\": \"Restaurant\"})\n",
    "\n",
    "# Normalize similarity and sentiment scores using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "hybrid_model[[\"Content_Score\", \"Sentiment_Score\"]] = scaler.fit_transform(\n",
    "    hybrid_model[[\"Content_Score\", \"Sentiment_Score\"]])\n",
    "\n",
    "# Compute final hybrid score (weighted sum of content and sentiment scores)\n",
    "hybrid_model[\"Hybrid_Score\"] = (\n",
    "    0.7 * hybrid_model[\"Content_Score\"] + 0.3 * hybrid_model[\"Sentiment_Score\"]\n",
    ")\n",
    "\n",
    "# Sort recommendations by Hybrid Score\n",
    "hybrid_model = hybrid_model.sort_values(by=[\"Restaurant\", \"Hybrid_Score\"], ascending=[True, False])\n",
    "\n",
    "# Display the first few rows\n",
    "print(hybrid_model.head())\n",
    "\n",
    "# Save the hybrid model recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(precision_list), np\u001b[38;5;241m.\u001b[39mmean(recall_list), np\u001b[38;5;241m.\u001b[39mmean(f1_list)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate hybrid model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m precision, recall, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_recommendation_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_interactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute AUC (if applicable)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_auc\u001b[39m(recommended_items, actual_items):\n",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m, in \u001b[0;36mevaluate_recommendation_system\u001b[0;34m(hybrid_df, actual_interactions, top_k)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_recommendation_system\u001b[39m(hybrid_df, actual_interactions, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     precision_list, recall_list, f1_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user, actual_restaurants \u001b[38;5;129;01min\u001b[39;00m actual_interactions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Get top-k recommended restaurants for the user\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         recommended_restaurants \u001b[38;5;241m=\u001b[39m hybrid_df[hybrid_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestaurant\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(actual_restaurants)]\u001b[38;5;241m.\u001b[39mnlargest(top_k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHybrid_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilar_Restaurant\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Function to evaluate recommendation system\n",
    "def evaluate_recommendation_system(hybrid_df, actual_interactions, top_k=5):\n",
    "    precision_list, recall_list, f1_list = [], []\n",
    "\n",
    "    for user, actual_restaurants in actual_interactions.items():\n",
    "        # Get top-k recommended restaurants for the user\n",
    "        recommended_restaurants = hybrid_df[hybrid_df[\"Restaurant\"].isin(actual_restaurants)].nlargest(top_k, \"Hybrid_Score\")[\"Similar_Restaurant\"].tolist()\n",
    "\n",
    "        if not recommended_restaurants:  # If no recommendations exist, set precision, recall, and f1 to 0\n",
    "            precision_list.append(0)\n",
    "            recall_list.append(0)\n",
    "            f1_list.append(0)\n",
    "            continue\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        relevant_recommendations = set(recommended_restaurants).intersection(set(actual_restaurants))\n",
    "        precision = len(relevant_recommendations) / len(recommended_restaurants) if recommended_restaurants else 0\n",
    "        recall = len(relevant_recommendations) / len(actual_restaurants) if actual_restaurants else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)  # Ensure all three values are returned\n",
    "\n",
    "# Re-run evaluation\n",
    "precision, recall, f1 = evaluate_recommendation_system(hybrid_model, actual_interactions, top_k=5)\n",
    "\n",
    "# Compute AUC (if applicable)\n",
    "def evaluate_auc(recommended_items, actual_items):\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "\n",
    "    for rec, actual in zip(recommended_items, actual_items):\n",
    "        for item in rec:\n",
    "            y_true.append(1 if item in actual else 0)\n",
    "            y_scores.append(1)  # Assume all recommendations have score=1\n",
    "\n",
    "    return roc_auc_score(y_true, y_scores) if len(set(y_true)) > 1 else 0  # Ensure AUC is computed properly\n",
    "\n",
    "recommended_items = [hybrid_model.groupby(\"Restaurant\").head(5)[\"Similar_Restaurant\"].tolist()]\n",
    "actual_items = [list(set(sum(actual_interactions.values(), [])))]  # Flatten actual interactions\n",
    "\n",
    "auc_score = evaluate_auc(recommended_items, actual_items)\n",
    "\n",
    "# Display evaluation results\n",
    "evaluation_results = pd.DataFrame({\n",
    "    \"Metric\": [\"Precision\", \"Recall\", \"F1-Score\", \"AUC\"],\n",
    "    \"Score\": [precision, recall, f1, auc_score]\n",
    "})\n",
    "\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
