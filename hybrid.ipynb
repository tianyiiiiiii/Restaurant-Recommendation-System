{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Restaurant  Sentiment_Score\n",
      "0               10 Downing Street             0.86\n",
      "1                        13 Dhaba             0.67\n",
      "2  3B's - Buddies, Bar & Barbecue             0.94\n",
      "3       AB's - Absolute Barbecues             0.98\n",
      "4               Absolute Sizzlers             0.68\n",
      "          Restaurant             Similar_Restaurant  Content_Score\n",
      "0  10 Downing Street                          SKYHY       0.675805\n",
      "1  10 Downing Street         Mustang Terrace Lounge       0.672156\n",
      "2  10 Downing Street  The Lal Street - Bar Exchange       0.659896\n",
      "3  10 Downing Street     La La Land - Bar & Kitchen       0.637958\n",
      "4  10 Downing Street     Over The Moon Brew Company       0.631628\n",
      "          Restaurant                    Similar_Restaurant  Item_CF_Score\n",
      "0  10 Downing Street                    Hunger Maggi Point       0.232301\n",
      "1  10 Downing Street                         Gal Punjab Di       0.172412\n",
      "2  10 Downing Street  Collage - Hyatt Hyderabad Gachibowli       0.136376\n",
      "3  10 Downing Street                                Faasos       0.096689\n",
      "4  10 Downing Street                       The Glass Onion       0.075676\n"
     ]
    }
   ],
   "source": [
    "sentiment_path = \"data hybrid/sentiment_scores.csv\" \n",
    "content_path = \"data hybrid/content_scores.csv\"\n",
    "item_cf_path = \"data hybrid/item_cf_scores.csv\"\n",
    "\n",
    "sentiment_scores = pd.read_csv(sentiment_path) \n",
    "content_scores = pd.read_csv(content_path)  \n",
    "item_cf_scores = pd.read_csv(item_cf_path) \n",
    "\n",
    "print(sentiment_scores.head())\n",
    "print(content_scores.head())\n",
    "print(item_cf_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hybird model of sentiment analysis + content-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Restaurant             Similar_Restaurant  Content_Score  \\\n",
      "4   10 downing street     over the moon brew company       0.722478   \n",
      "2   10 downing street  the lal street - bar exchange       0.757282   \n",
      "0   10 downing street                          skyhy       0.776870   \n",
      "1   10 downing street         mustang terrace lounge       0.772377   \n",
      "10  10 downing street           prism club & kitchen       0.651262   \n",
      "\n",
      "    Sentiment_Score  Hybrid_Score  \n",
      "4          0.907692      0.778042  \n",
      "2          0.646154      0.723944  \n",
      "0          0.600000      0.723809  \n",
      "1          0.569231      0.711433  \n",
      "10         0.830769      0.705114  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Normalize restaurant names for consistency\n",
    "for df in [sentiment_scores, content_scores]:\n",
    "    df[\"Restaurant\"] = df[\"Restaurant\"].str.strip().str.lower()\n",
    "    if \"Similar_Restaurant\" in df.columns:\n",
    "        df[\"Similar_Restaurant\"] = df[\"Similar_Restaurant\"].str.strip().str.lower()\n",
    "\n",
    "# Merge content-based filtering scores with sentiment scores of the similar restaurant\n",
    "hybrid_model = content_scores.merge(sentiment_scores, left_on=\"Similar_Restaurant\", right_on=\"Restaurant\", how=\"left\")\n",
    "\n",
    "# Drop duplicate Restaurant column\n",
    "hybrid_model = hybrid_model.drop(columns=[\"Restaurant_y\"]).rename(columns={\"Restaurant_x\": \"Restaurant\"})\n",
    "\n",
    "# Normalize similarity and sentiment scores using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "hybrid_model[[\"Content_Score\", \"Sentiment_Score\"]] = scaler.fit_transform(\n",
    "    hybrid_model[[\"Content_Score\", \"Sentiment_Score\"]])\n",
    "\n",
    "# Compute final hybrid score (weighted sum of content and sentiment scores)\n",
    "hybrid_model[\"Hybrid_Score\"] = (\n",
    "    0.7 * hybrid_model[\"Content_Score\"] + 0.3 * hybrid_model[\"Sentiment_Score\"]\n",
    ")\n",
    "\n",
    "# Sort recommendations by Hybrid Score\n",
    "hybrid_model = hybrid_model.sort_values(by=[\"Restaurant\", \"Hybrid_Score\"], ascending=[True, False])\n",
    "\n",
    "# Display the first few rows\n",
    "print(hybrid_model.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric     Score\n",
      "0  Precision  0.066667\n",
      "1     Recall  0.166667\n",
      "2   F1-Score  0.095238\n",
      "3        AUC  0.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Function to evaluate recommendation system\n",
    "def evaluate_recommendation_system(hybrid_df, actual_interactions, top_k=5):\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "\n",
    "    for user, actual_restaurants in actual_interactions.items():\n",
    "        # Get top-k recommended restaurants for the user\n",
    "        recommended_restaurants = hybrid_df[hybrid_df[\"Restaurant\"].isin(actual_restaurants)] \\\n",
    "                                    .nlargest(top_k, \"Hybrid_Score\")[\"Similar_Restaurant\"].tolist()\n",
    "\n",
    "        if not recommended_restaurants:  # If no recommendations exist, set precision, recall, and f1 to 0\n",
    "            precision_list.append(0)\n",
    "            recall_list.append(0)\n",
    "            f1_list.append(0)\n",
    "            continue\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        relevant_recommendations = set(recommended_restaurants).intersection(set(actual_restaurants))\n",
    "        precision = len(relevant_recommendations) / max(len(recommended_restaurants), 1)  # Avoid division by zero\n",
    "        recall = len(relevant_recommendations) / max(len(actual_restaurants), 1)  # Avoid division by zero\n",
    "        f1 = (2 * precision * recall) / max((precision + recall), 1e-9)  # Avoid division by zero\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    # Ensure that all three values are always returned\n",
    "    precision_avg = np.mean(precision_list) if precision_list else 0\n",
    "    recall_avg = np.mean(recall_list) if recall_list else 0\n",
    "    f1_avg = np.mean(f1_list) if f1_list else 0\n",
    "\n",
    "    return precision_avg, recall_avg, f1_avg\n",
    "\n",
    "# Re-run evaluation\n",
    "precision, recall, f1 = evaluate_recommendation_system(hybrid_model, actual_interactions, top_k=5)\n",
    "\n",
    "# Compute AUC (if applicable)\n",
    "def evaluate_auc(hybrid_df, actual_interactions, top_k=5):\n",
    "    y_true, y_scores = [], []\n",
    "\n",
    "    for user, actual_restaurants in actual_interactions.items():\n",
    "        recommended_restaurants = hybrid_df[hybrid_df[\"Restaurant\"].isin(actual_restaurants)] \\\n",
    "                                    .nlargest(top_k, \"Hybrid_Score\")[\"Similar_Restaurant\"].tolist()\n",
    "\n",
    "        for item in recommended_restaurants:\n",
    "            y_true.append(1 if item in actual_restaurants else 0)\n",
    "            y_scores.append(1)  # Assign score of 1 for all recommendations\n",
    "\n",
    "    return roc_auc_score(y_true, y_scores) if len(set(y_true)) > 1 else 0  # Ensure AUC is computable\n",
    "\n",
    "auc_score = evaluate_auc(hybrid_model, actual_interactions, top_k=5)\n",
    "\n",
    "# Display evaluation results\n",
    "evaluation_results = pd.DataFrame({\n",
    "    \"Metric\": [\"Precision\", \"Recall\", \"F1-Score\", \"AUC\"],\n",
    "    \"Score\": [precision, recall, f1, auc_score]\n",
    "})\n",
    "\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
